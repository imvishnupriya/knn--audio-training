# ğŸŒ³ IASN KNN Acoustic Event Detection Pipeline

A real-time monitoring system for illegal logging and environmental acoustic events using intelligent acoustic sensor nodes (IASN). Uses low-level feature extraction (LLFs) with Short-Time Hartley Transform (STHT) and classifies acoustic events using a K-Nearest Neighbors (KNN) classifier.

---

## ğŸ“‚ Project Structure
```bash
knn-audio-training/
â”‚
â”œâ”€â”€ index.py # Main orchestrator: runs the entire pipeline
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ init.py # Package marker (empty)
â”‚ â”œâ”€â”€ split_audio.py # Splits long raw audios into 1s clips for training
â”‚ â”œâ”€â”€ visualize_spectrograms.py # Visualizes STHT spectrograms for each class
â”‚ â”œâ”€â”€ train_model.py # Trains and saves the KNN model
â”‚ â””â”€â”€ test_model.py # Tests new audio using the trained model
â”‚
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ init.py # Package marker (empty)
â”‚ â”œâ”€â”€ audio_utils.py # Splitting, loading clips, etc.
â”‚ â””â”€â”€ feature_extraction.py # STHT and LLF extraction
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw_audio/ # Place raw long .mp3/.wav recordings here
â”‚ â”œâ”€â”€ dataset_clips/ # Auto-generated 1s clips for training
â”‚ â””â”€â”€ test_audio/ # Place test audios for classification here
â”‚
â”œâ”€â”€ models/ # Saved KNN model, scaler, and label encoder
â”‚
â”œâ”€â”€ requirements.txt # Required Python libraries
â””â”€â”€ README.md # Project overview and instructions
```
---

## ğŸ¯ Project Goals

- Detect illegal logging activities using acoustic features.
- Differentiate between forest sounds, vehicle noise, speech, and logging events.
- Enable real-time, low-power edge deployment using lightweight feature extraction and KNN.
- Provide visual tools for dataset sanity checking and result analysis.

---

## âš™ï¸ Installation

âœ… Ensure Python 3.8+ is installed.

âœ… Install dependencies:
```bash
pip install -r requirements.txt
ğŸš€ Pipeline Execution
Run the full pipeline:

python index.py
This will:

Split long raw audios into clips.

Visualize STHT spectrograms for each class.

Train the KNN model and save to models/.

Test new audio in data/test_audio/ and display per-clip + majority predictions.

Manual Step-by-Step:
Split raw audio:


python -m scripts.split_audio
Visualize spectrograms:


python -m scripts.visualize_spectrograms
Train the model:


python -m scripts.train_model
Test on new field data:


python -m scripts.test_model
ğŸ¨ Features
STHT-based spectrogram generation.

16 LLFs per frame (energy, centroid, bandwidth, entropy, etc.).

Visual data inspection.

KNN classification with per-clip prediction and majority voting.

tqdm progress bars for transparency.

Modular, scalable structure ready for CNN/LSTM if needed.

ğŸ“ˆ Potential Extensions
Batch test multiple field recordings automatically.

Log classification results to CSV.

Add confusion matrices for analysis.

ONNX/TFLite export for microcontroller deployment.

Real-time edge streaming and alert integration.

ğŸ¤ Contributing
Contributions welcome for enhancements such as batch testing, cloud integration, or model improvements.

